#!/bin/bash
 
# --------------------------------------------------------------
### PART 1: Requests resources to run your job.
# --------------------------------------------------------------
### Optional. Set the job name
#SBATCH --job-name=mirageWASP80Rapid
### Optional. Set the output filename.
### SLURM reads %x as the job name and %j as the job ID
#SBATCH --output=%x-%j.out
### REQUIRED. Specify the PI group for this job
#SBATCH --account=eas342
### Optional. Request email when job begins and ends
#SBATCH --mail-type=ALL
### Optional. Specify email address to use for notification
#SBATCH --mail-user=eas342@email.arizona.edu
### REQUIRED. Set the partition for your job.
#SBATCH --partition=standard
### REQUIRED. Set the number of cores that will be used for this job.
#SBATCH --ntasks=10
### REQUIRED. Set the memory required for this job.
#SBATCH --mem=256gb
### REQUIRED. Specify the time required for this job, hhh:mm:ss
#SBATCH --time=24:00:00
 
 
# --------------------------------------------------------------
### PART 2: Executes bash commands to run your job
# --------------------------------------------------------------
### Load required modules/libraries if needed
###    module load anaconda 
###    conda activate /home/u17/eas342/miniconda2/envs/mirage
### This one gave me a n error:
### CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
### old fashioned way
export PATH=/home/u17/eas342/miniconda2/bin:$PATH
source activate mirage

### change to your scriptâ€™s directory
cd /xdisk/eas342/eas342/mirage_runs
python NIRCam_grism_tso_wrapper.py mirage_input_005_wasp80rapid/source_params_wasp80rapid.yaml

sleep 10
